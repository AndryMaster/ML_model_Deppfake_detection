## Текст выступления для защиты проекта "Распознавание дипфейков посредством нейронных сетей" (IT-Планета 2025)

**(Слайд 1: Наименование и команда)**

Здравствуйте, уважаемые эксперты! Я, подготовил проект 
"Распознавание дипфейков посредством нейронных сетей".

**(Слайд 2: Тема и цель проекта)**

Проблема распространения дипфейков становится все более актуальной,
и появляется спрос на инструменты для борьбы с ними.

Поэтому тема моего проекта – разработка классификатора изображений
для обнаружения дипфейков (в моем исследовании это поддельные человеческие лица).

Цель проекта – создать прототип, способный отличать поддельные
изображения от настоящих, используя методы машинного обучения.
При чем нейросеть имеет возможность запускаться локально.

**(Слайд 3: Целевая аудитория)**

Основной целевевой аудиторией будущего продукта являются стороны заинтересованные
в автоматической проверке подлинности изображений с определенной точностью.
Это могут быть как пользователи,
желающие убедиться в достоверности какого-либо изображения,
так и организации, работающие с медиа-контентом и
нуждающиеся в инструментах для выявления фейков.

**(Слайд 4: Основная идея и этапы)**

Основная идея – создать и обучить нейросеть.
Для этого я исследовал различные архитектуры нейронных сетей,
включая ResNet, SqueezeNext и ViT. 

Этапы реализации включали:
* подготовку датасета (содержащего почти 200к картинок) - это открытый датасет к Kaggle
* обучение моделей на различных архитектурах
* и сравнение их эффективности

**(Слайд 5: Функционал прототипа)**

Прототип позволяет загружать изображения
размером 256x256 пикселей и получать прогноз о достоверности
каждого из них.

**(Слайд 6: Используемые технологии)**

Для реализации я использовал **PyTorch** – это популярный фреймворк
для машинного обучения на Python.
Он поддреживает полный цикл разработки и тестирования нейронных сетей,
и использует графический процессор для ускорения вычислений.

В решении я реализовал гибкую настройку, как самих архитектур моделей 
(можно настраивать количество слоёв, их ширину и другие параметры),
так и гибкую настройку процесса обучения (можно настраивать размер пакета,
частоту обучения оптимизатором, автоматическая сохранение и остановка
при начале переобучение и другие)

**(Слайд 7-9: Метрики и сравнение моделей)**

Дальше на слайдах показано сравнение разных обученных моделей
на архитектурах **ResNet, SqueezeNeXt, ViT**

* 7 - на этом слайде мы видим
  * матрицу предсказаний для лучшей модели сверху-справа
  * гистограмму с метриками потерь слева
  * и с другими метриками точности справа
* 8
  * здесь слева представлено колличество операций сложения, умножения за прогон,
    что аналогично времени обработки пакета (обратно быстродействию).
  * справа сверху видим колличество парматров у каждой модели
  * а ниже расположена гистограмма использования памяти при работе
* 9 - на этом слайде можно увидеть визуализацию предсказаний модели совместно с изображениями
  (зеленым то что модель предсказала правильно - а красным, там где модель ошиблась)

Подводя итог сравнению можно сказать, что:
* SqueezeNeXt - меньше остальных весит на диске (т.к. у модели мало параметров) 
  что дает нам порядка пары мегабайт на модель. И она
  довольно быстро обрабатывает изображения
* ResNet - дольше обрабатывает изображения, но показал наилучшую точность на
  тестовом наборе (более 90%, а на валидационном почти 97%)
* ViT - показал большую скорость обработки несмотря на размер. И большой потенциал
  к повышению точности, хоть она у него не высокая, он почти не начал переобучение.
  Вероятно, ему просто не хватило размера датасета,
  иначе он обладал бы значительно более высокой точностью.

Лучшей по точности моделью оказалась модель на архитектуре ResNet(-18). 
Модель имеет 12М параметров (и весит около 50МБ), при работе потребляет 3ГБ видеопамяти.
На тестовом наборе точность составила чуть больше 90%, f1-метрика составила 0,92.
Ее скорость на моем стенде - около 3000 изображений в секунду,
а методами оптимизации можно значительно увеличить скорость.

**(Слайд 10: Дальнейшее развитие)**

В будущем возможно значительно расширить возможности прототипа. 
(Например добавить обработку видео и аудио)

Первым шагом станет улучшение точности модели за счет
использования более сложных архитектур и увеличения объема обучающих данных.

Далее в планах может быть написание API и перевод прототипа в 
полноценный продукт. Используя Docker и CI/CD, сервис
можно будет легко развернуть на облачном кластере,
что дает продукту масштабируемость и быстодейстие.

**(Слайд 11: Финансовая модель и себестоимость)**

На этапе прототипа значительных финансовых затрат не было, только личное время.

В перспективе, финансовая модель проекта скорее всего будет
схожа с сервисами чатов языковых моделей – бесплатный план либо
подписка на использование API и более широкие возможности.

**(Слайд 12: Будущие планы)**

В планах на будущее переход от прототипа к готовому решению,
как было сказано в пункте _Дальнейшее развитие_

А также поддержка актуальности продукта,
за счет более современных методов обнаружения и борьбы с дипфейками

**(Слайд 13: Заключение)**

За время конкурса был разработан первый прототип классификатора изображений для 
обнаружения дипфейков. В ходе исследования протестированы 
некоторые архитектуры нейронных сетей.

Модель имеет потенциал для дальнейшего улучшения, а также план 
по переходу к готовому продукту.

А дальнейшее развитие этого проекта позволит создать еще один 
инструмент для борьбы с дипфейками.

**(Слайд 14: Спасибо за внимание)**

Спасибо за внимание


**Важные замечания:**

*   **Адаптируйте текст:** Этот текст – основа, адаптируйте его под свои собственные результаты и особенности проекта.
*   **Практикуйтесь:** Обязательно отрепетируйте свою презентацию несколько раз, чтобы уложиться в отведенное время (7 минут на выступление + 3 минуты на вопросы).
*   **Будьте готовы к вопросам:** Подумайте, какие вопросы могут задать эксперты и подготовьте ответы.
*   **Уверенность:** Говорите уверенно и с энтузиазмом о своем проекте!

Удачи на конкурсе!**


Сравнение с другими продуктами?

Сравнение проводилось. С учетом того что моя модель имеет небольшие размеры, что
позволяет запускать модель локально на компьютере среднего класса и выше. Поэтому модель
уступает серверным решениям, но показывает достойный результат.

При наличии мощного сервера возможно обучение больших моделей и следовательно повышение точности.
